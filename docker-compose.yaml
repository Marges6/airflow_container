
x-spark-common: &spark-common
  image: bitnami/spark:3.5.3-debian-12-r2
  volumes:
    - ./spark_jobs:/opt/bitnami/spark/jobs  
#  networks: 
#    - airflow_network

x-spark-worker-common: &spark-worker-common
  <<: *spark-common
  command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
  depends_on:
    - spark-master
  environment:
    - SPARK_MODE=worker
    - SPARK_WORKER_CORES=1
    - SPARK_WORKER_MEMORY=2g
    - SPARK_MASTER_URL=spark://spark-master:7077



x-airflow-common: &airflow-common
  build:
    context: .
    dockerfile: Dockerfile 
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./sql_scripts:/opt/airflow/sql_scripts
    - ./ssl_certs:/opt/airflow/ssl_certs
    - ./airflow/stg_postgres_conn.json:/opt/airflow/stg_postgres_conn.json
    - ./spark_jobs:/opt/airflow/spark_jobs
  env_file:
    .env
  entrypoint: /bin/bash
 # networks:
 #   - airflow_network


services:
  postgres:
    image: postgres:12
    ports:
      - "5433:5433"
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_DB=airflow
      - POSTGRES_PASSWORD=airflow
    volumes:
      - ./postgres/:/var/lib/postgresql/data
    command: -p 5433
 #   networks: 
 #     - airflow_network
    #alias: postgres


#  init-db:
#      <<: *airflow-common 
#      depends_on:
#          - postgres
#      environment: 
#        AIRFLOW_CONN_SOURCE_MSSQL: mssql://${AIRFLOW_MSSQL_USER}:${AIRFLOW_MSSQL_PASSWORD}@${MSSQL_HOST_IP_ADDRESS}:1433/AdventureWorks2022
##        AIRFLOW_CONN_STG_POSTGRES: cat /opt/airflow/stg_postgres_conn.json
#      command: -c "airflow db reset -y; \
#                airflow db migrate ; \
#                airflow users create --username airflow --password password --firstname M --lastname G --role Admin --email admin@admin.com; \
#                airflow connections add source_mssql --conn-uri $$AIRFLOW_CONN_SOURCE_MSSQL; \
#                AIRFLOW_CONN_STG_POSTGRES="`cat /opt/airflow/stg_postgres_conn.json`"; \
#                airflow connections add stg_postgres --conn-json \"$$AIRFLOW_CONN_STG_POSTGRES\"" 

  webserver:
    <<: *airflow-common
    depends_on:
      - scheduler
    ports:
      - "8080:8080"
    command: -c "airflow webserver"
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 2
    restart: always

  scheduler:
    <<: *airflow-common
    depends_on:
      - postgres
    command: -c "airflow scheduler"
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 2
    restart: always
  
  spark-master:
    <<: *spark-common
    command: bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "9090:8080" 
      - "7077:7077"

  spark-worker-1:
    <<: *spark-worker-common
  
#  spark-worker-2:
#    <<: *spark-common
#
#networks:
#  airflow_network:
#    driver: bridge 
#    ipam:
#      config: 
#        - subnet: 172.20.0.0/16
#          gateway: 172.20.0.1

      


   